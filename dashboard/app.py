"""
Streamlit Dashboard for LLM Response Evaluation

This is the user interface for the evaluation system. It provides:
- Input form for question/context/response
- Real-time evaluation
- Visual results display
- Metric breakdowns

What is Streamlit?
- Python library for creating web apps
- No HTML/CSS/JavaScript needed!
- Perfect for data science dashboards
- Updates automatically as code changes

Key Streamlit concepts:
- st.text_input(): Input boxes
- st.text_area(): Multi-line text input
- st.button(): Buttons
- st.metric(): Display metrics
- st.progress(): Progress bars
- st.json(): Display JSON data

To run:
    streamlit run dashboard/app.py
"""

import streamlit as st
import requests
import json
from datetime import datetime
import time

# Page configuration
st.set_page_config(
    page_title="LLM Response Evaluator",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API configuration
API_URL = "http://localhost:8000"

# Custom CSS for better styling
st.markdown("""
    <style>
    .big-font {
        font-size:20px !important;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)

# Title and description
st.title("üß† LLM Response Evaluation System")
st.markdown("""
Evaluate LLM responses across 5 key quality metrics:
**Hallucination Detection** | **Groundedness** | **Faithfulness** | **Context Relevance** | **Completeness**
""")

# Sidebar configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    st.subheader("Evaluation Thresholds")
    hallucination_threshold = st.slider(
        "Hallucination Threshold",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.05,
        help="Lower = more sensitive to contradictions (recommended: 0.3)"
    )
    
    groundedness_threshold = st.slider(
        "Groundedness Threshold",
        min_value=0.0,
        max_value=1.0,
        value=0.4,
        step=0.05,
        help="Minimum score for claims to be considered grounded (recommended: 0.4)"
    )
    
    relevance_threshold = st.slider(
        "Relevance Threshold",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="Minimum score for context to be considered relevant (recommended: 0.5)"
    )
    
    st.divider()
    
    st.subheader("üìä About")
    st.info("""
    This dashboard evaluates LLM responses using state-of-the-art NLP models:
    - **NLI Models**: facebook/bart-large-mnli
    - **Embeddings**: all-MiniLM-L6-v2
    - **Cross-Encoder**: ms-marco-MiniLM-L-6-v2
    """)
    
    # API Health Check
    st.divider()
    st.subheader("üè• API Status")
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        if response.status_code == 200:
            st.success("‚úÖ API is running")
        else:
            st.error("‚ùå API is not responding")
    except:
        st.error("‚ùå Cannot connect to API")
        st.info("Make sure to start the API server:\n```\npython -m uvicorn app.main:app --reload\n```")

# Main content
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üìù Input")
    
    # Input fields
    question = st.text_input(
        "Question",
        placeholder="e.g., What is machine learning?",
        help="The question that was asked to the LLM"
    )
    
    context = st.text_area(
        "Context (Source Material)",
        height=150,
        placeholder="Paste the context/source material that was provided to the LLM...",
        help="The source context that should ground the LLM's response"
    )
    
    llm_response = st.text_area(
        "LLM Response",
        height=150,
        placeholder="Paste the LLM's response here...",
        help="The response generated by the LLM that you want to evaluate"
    )
    
    # Example button
    if st.button("üìã Load Example"):
        st.session_state.example_loaded = True
        question = "What is Python and when was it created?"
        context = "Python is a high-level, interpreted programming language created by Guido van Rossum. It was first released in 1991."
        llm_response = "Python is a programming language developed by Guido van Rossum and released in 1991."
        st.rerun()
    
    # Evaluate button
    evaluate_button = st.button("üöÄ Evaluate Response", type="primary", use_container_width=True)

with col2:
    st.header("üìä Results")
    
    # Results container
    results_container = st.container()

# Process evaluation when button is clicked
if evaluate_button:
    if not question or not context or not llm_response:
        st.error("‚ö†Ô∏è Please fill in all fields before evaluating!")
    else:
        with st.spinner("üîÑ Evaluating... This may take 10-30 seconds..."):
            try:
                # Call API
                payload = {
                    "question": question,
                    "context": context,
                    "llm_response": llm_response,
                    "hallucination_threshold": hallucination_threshold,
                    "groundedness_threshold": groundedness_threshold,
                    "relevance_threshold": relevance_threshold
                }
                
                response = requests.post(
                    f"{API_URL}/api/evaluate",
                    json=payload,
                    timeout=60
                )
                
                if response.status_code == 200:
                    result = response.json()
                    
                    with results_container:
                        # Overall Score
                        st.markdown("### üéØ Overall Quality Score")
                        
                        score_col1, score_col2, score_col3 = st.columns([2, 1, 1])
                        
                        with score_col1:
                            st.metric(
                                label="Overall Score",
                                value=f"{result['overall_score_100']:.1f}/100",
                                delta=result['quality_tier']
                            )
                        
                        with score_col2:
                            st.metric(
                                label="Quality Tier",
                                value=f"{result['emoji']} {result['quality_tier']}"
                            )
                        
                        with score_col3:
                            st.metric(
                                label="Time",
                                value=f"{result['execution_time_seconds']:.2f}s"
                            )
                        
                        # Progress bar for overall score
                        st.progress(result['overall_score'])
                        
                        # Issues
                        if result['has_issues']:
                            st.warning(f"‚ö†Ô∏è {len(result['issues'])} Issue(s) Detected")
                            for issue in result['issues']:
                                st.markdown(f"- {issue}")
                        else:
                            st.success("‚úÖ No major issues detected!")
                        
                        st.divider()
                        
                        # Individual Metrics
                        st.markdown("### üìà Metric Breakdown")
                        
                        metrics = result
                        
                        # Create metric cards
                        metric_col1, metric_col2 = st.columns(2)
                        
                        with metric_col1:
                            # Hallucination
                            st.markdown("#### üîç Hallucination Detection")
                            hal_score = metrics['hallucination']['score'] * 100
                            st.progress(metrics['hallucination']['score'])
                            st.metric("Score", f"{hal_score:.1f}%")
                            if metrics['hallucination']['has_hallucination']:
                                st.error(f"‚ö†Ô∏è Hallucination detected! ({metrics['hallucination']['label']})")
                            else:
                                st.success("‚úÖ No hallucinations")
                            
                            # Groundedness
                            st.markdown("#### üìä Groundedness")
                            ground_score = metrics['groundedness']['score'] * 100
                            st.progress(metrics['groundedness']['score'])
                            st.metric("Score", f"{ground_score:.1f}%")
                            st.caption(f"{metrics['groundedness']['num_supported']}/{metrics['groundedness']['num_claims']} claims supported")
                            if metrics['groundedness']['unsupported_claims']:
                                with st.expander("View unsupported claims"):
                                    for claim in metrics['groundedness']['unsupported_claims']:
                                        st.markdown(f"- {claim}")
                            
                            # Faithfulness
                            st.markdown("#### üíé Faithfulness")
                            faith_score = metrics['faithfulness']['score'] * 100
                            st.progress(metrics['faithfulness']['score'])
                            st.metric("Score", f"{faith_score:.1f}%")
                            st.caption(f"Semantic similarity: {metrics['faithfulness']['similarity']:.3f}")
                        
                        with metric_col2:
                            # Relevance
                            st.markdown("#### üéØ Context Relevance")
                            rel_score = metrics['relevance']['score'] * 100
                            st.progress(metrics['relevance']['score'])
                            st.metric("Score", f"{rel_score:.1f}%")
                            if metrics['relevance']['is_relevant']:
                                st.success("‚úÖ Context is relevant")
                            else:
                                st.warning("‚ö†Ô∏è Context may not be relevant")
                            st.caption(metrics['relevance']['interpretation'])
                            
                            # Completeness
                            st.markdown("#### ‚úÖ Answer Completeness")
                            comp_score = metrics['completeness']['score'] * 100
                            st.progress(metrics['completeness']['score'])
                            st.metric("Score", f"{comp_score:.1f}%")
                            st.caption(f"{metrics['completeness']['num_addressed']}/{metrics['completeness']['num_aspects']} aspects addressed")
                            if metrics['completeness']['missing_aspects']:
                                with st.expander("View missing aspects"):
                                    for aspect in metrics['completeness']['missing_aspects']:
                                        st.markdown(f"- {aspect}")
                        
                        st.divider()
                        
                        # Raw JSON
                        with st.expander("üîß View Raw JSON Response"):
                            st.json(result)
                
                else:
                    st.error(f"‚ùå API Error: {response.status_code}")
                    st.json(response.json())
                    
            except requests.exceptions.ConnectionError:
                st.error("‚ùå Cannot connect to API. Make sure the API server is running:")
                st.code("python -m uvicorn app.main:app --reload", language="bash")
            except requests.exceptions.Timeout:
                st.error("‚è±Ô∏è Request timed out. The evaluation took too long.")
            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>LLM Response Evaluation System v1.0 | Built with ‚ù§Ô∏è using FastAPI & Streamlit</p>
    <p>API Docs: <a href='http://localhost:8000/docs' target='_blank'>Swagger UI</a></p>
</div>
""", unsafe_allow_html=True)
